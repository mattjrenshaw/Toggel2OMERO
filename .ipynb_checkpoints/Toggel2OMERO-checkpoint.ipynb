{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e00f1fe8-54b4-4a82-aab1-f632b924d0b8",
   "metadata": {},
   "source": [
    "# Import Frequency Domain FLIM data to OMERO\n",
    "*Matt Renshaw* \n",
    "*CALM STP*\n",
    "*The Francis Crick Institute*\n",
    "*2025-09-18*  \n",
    "\n",
    "**Background**: Using the Micro-Manager device adapter for the Toggel Frequency Domain FLIM (FD_FLIM) camera (Lambert Instruments) outputs the raw phase image series in the Lambert Instruments Lifa format (.fli files) as well as Micro-Manager .ome.tif files that contain acquisition metadata and fitted lifetime values as image channels. Although the fitted lifetime values can be used for basic analysis in simple FLIM experiments, they assume a single component population for the fitting that can make FRET experiments difficult to interpret. Phasor plots allow for fitting-independent analysis of FLIM data, but require processing of the phase image series. \n",
    "\n",
    "**Aim**: Facilitate analysis of FD-FLIM data by uploading phase image series to OMERO, linking the image data to acquisition and experimental metadata, and processing the phase data to generate s and g values for phasor plots as well as fitted lifetime values.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c5b8c49-8f42-4ccb-b241-92b8d15b51ab",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "1. [Setup](#setup)\n",
    "2. [Upload FD FLIM data to OMERO](#fli-to-omero)\n",
    "3. [Read metadata and process phase series](#read-metadata-and-process-images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4376ff24-8078-4a1c-bb4d-d2fbfb1ca82a",
   "metadata": {},
   "source": [
    "## Setup <a id=\"setup\"></a>\n",
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6219ff5d-a333-4427-8ad5-e89da0f5802f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import Toggel_utils as toggel\n",
    "import omero_utils as omero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9072d97-763e-4e48-a4f1-3b50ce6271ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import tifffile\n",
    "import json\n",
    "import os\n",
    "from joblib import Parallel, delayed\n",
    "from scipy.optimize import curve_fit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3a0ab9-fb3f-4c42-9e39-207458231876",
   "metadata": {},
   "source": [
    "## Upload FD FLIM data to OMERO <a id=\"fli-to-omero\"></a>\n",
    "1. Define path to directory containing raw .fli files\n",
    "2. Connect to OMERO\n",
    "3. FLI reader to read image planes, camera dark image and metadata\n",
    "4. Subtracts camera dark image from each phase image\n",
    "5. Uploads phase image series to OMERO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27722e0c-13a7-4733-91af-a0da2e825eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define path to folder containing raw .fli files\n",
    "# dir_path = r'C:\\Users\\rensham\\OneDrive - The Francis Crick Institute\\repositories\\temp_files'\n",
    "dir_path = r'N:\\outputs\\treismanr\\fromMatt_Toggel\\20250905\\raw'\n",
    "omero_host = \"omero-training.thecrick.org\" # optional: defaults to "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511d2eb8-5cb7-4fff-8ca6-184d0e678900",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to OMERO\n",
    "conn = omero.connect(\"rensham\", host = omero_host)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6883021c-3c7e-4898-8ab6-3712d2a611fd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# process all .fli files in dir_path\n",
    "\n",
    "folder = Path(dir_path) # string to Path\n",
    "\n",
    "project_name = \"Toggel\" # store all Toggel phase series within same 'Toggel' project\n",
    "dataset_name = folder.stem\n",
    "\n",
    "project_object = omero.create_project(conn, project_name) # get or create project called project_name\n",
    "project_id = project_object.getId()\n",
    "\n",
    "dataset_object = omero.create_dataset(conn, dataset_name, project_id) # get or create dataset called dataset_name within project_id\n",
    "dataset_id = dataset_object.getId()\n",
    "\n",
    "for file in folder.glob(\"*.fli\"):\n",
    "    filename = file.stem\n",
    "    acquisition_datetime = filename[0:19]\n",
    "    print(filename)\n",
    "\n",
    "    # read .fli file and get metadata    \n",
    "    md, phase_images, dark_image = toggel.read_fli_file(file)\n",
    "    sizeX, sizeY, n_phases, mod_frequency = (md['LAYOUT'].get(key) for key in ('x', 'y', 'phases', 'modulationFrequency'))\n",
    "    sensor_gain, ref = (md['ACQUISITION SETTINGS'].get(key) for key in ('sensorGain', 'RefLifetime'))\n",
    "    \n",
    "    if float(ref) > 0:\n",
    "        acquisition_type = \"reference\"\n",
    "    else:\n",
    "        acquisition_type = \"sample\"\n",
    "\n",
    "    key_value_pairs = []\n",
    "    key_value_pairs.append([\"Imaging Modality\", \"Frequency Domain FLIM\"])\n",
    "    key_value_pairs.append([\"acquisition_datetime\", str(acquisition_datetime)])\n",
    "    key_value_pairs.append([\"n_phases\", str(n_phases)])\n",
    "    key_value_pairs.append([\"modulation_frequency_Hz\", str(mod_frequency)])\n",
    "    key_value_pairs.append([\"sensor_gain\", str(sensor_gain)])\n",
    "    key_value_pairs.append([\"reference_lifetime_ns\", str(ref)])\n",
    "    key_value_pairs.append([\"acquisition_type\", str(acquisition_type)])\n",
    "\n",
    "    # subtract camera dark image from phase images\n",
    "    phase_series = np.empty_like(phase_images, dtype=np.float32)\n",
    "    for ph, plane in enumerate(phase_images):\n",
    "        phase_series[ph] = plane.astype(np.float32) - dark_image.astype(np.float32)\n",
    "\n",
    "    # upload images to OMERO\n",
    "    image_obj = omero.create_image(conn, filename, dataset_id, key_value_pairs, phase_series, channel_names=None,\n",
    "                             sizeT=int(n_phases), \n",
    "                             description=\"FD FLIM phase images\")\n",
    "\n",
    "if (conn):\n",
    "    conn.close()\n",
    "    \n",
    "print(f'OMERO project id for phase series images: {project_id}')    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e503763-3120-4774-81fe-d66dd04301ce",
   "metadata": {},
   "source": [
    "## Read metadata and process phase series <a id=\"read-metadata-and-process-images\"></a>\n",
    "1. Select .csv file that contains paths to .ome.tif files and experimental metadata\n",
    "2. Connect to OMERO\n",
    "3. Define toggel_project_id: OMERO project ID that contains the phase image series datasets\n",
    "4. Loops through .ome.tif files: reads metadata, identifies reference and sample phase images series for each FLIM record\n",
    "5. Processes phase image series to fitted lifetime values, mean intensity, s and g values\n",
    "6. Uploads processed images to OMERO, with links to sample and reference image IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e751fb27-efd8-49a0-88d7-0ae38ba714dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open file dialog and select experimental metadata .csv file\n",
    "path_to_exp_info = toggel.get_filepath()\n",
    "\n",
    "print(\"path to experimental metadata file:\", path_to_exp_info)\n",
    "# read .csv file as pandas dataframe\n",
    "df = pd.read_csv(path_to_exp_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd2b9d2-7e47-49e0-9b54-cce8dfcf3054",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to OMERO\n",
    "conn = omero.connect(\"rensham\", host = omero_host)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0831611d-96f4-4dcb-a0fb-cf9a588e702f",
   "metadata": {},
   "outputs": [],
   "source": [
    "toggel_project_id = 102 # OMERO project ID containing the phase image series\n",
    "\n",
    "# initialise variables\n",
    "pos_dict = {}\n",
    "current_ref_id = None\n",
    "\n",
    "# get lists of phase series image names\n",
    "ref_names = omero.find_image_names_in_project_kv_dict(conn, toggel_project_id, {\"acquisition_type\": \"reference\"})\n",
    "sample_names = omero.find_image_names_in_project_kv_dict(conn, toggel_project_id, {\"acquisition_type\": \"sample\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc33c1ac-bef1-4fea-bc30-eb07070fa3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select Frequency Domain FLIM rows\n",
    "selected = df[df[\"Imaging Method\"]==\"Frequency Domain FLIM\"] # select FLIM datasets\n",
    "list_of_projects = selected[\"Project\"].unique() # select unique list of \"Projects\". Note: the term Projects is used to align with the OMERO data structure\n",
    "\n",
    "for project in list_of_projects:\n",
    "    subset = selected[selected[\"Project\"] == project]\n",
    "    \n",
    "    # generate unique full paths to MicroManager datasets\n",
    "    list_of_paths = []\n",
    "    unique_paths = subset[[\"Parent Directory\", \"Project\", \"Dataset\"]].drop_duplicates().reset_index()\n",
    "    for idx, row in unique_paths.iterrows():\n",
    "        path = Path(os.path.join(\n",
    "            str(row[\"Parent Directory\"]),\n",
    "            str(row[\"Project\"]),\n",
    "            str(row[\"Dataset\"]))\n",
    "        )\n",
    "        if path.exists() & path.is_dir():\n",
    "            list_of_paths.append(path)\n",
    "\n",
    "    # create OMERO Project\n",
    "    project_name = str(project)\n",
    "    project_object = omero.create_project(conn, project_name) # get or create project called project_name\n",
    "    project_id = project_object.getId()\n",
    "\n",
    "    for folder in list_of_paths:\n",
    "        dataset_name = folder.stem\n",
    "        dataset_object = omero.create_dataset(conn, dataset_name, project_id) # get or create dataset called dataset_name within project_id\n",
    "        dataset_id = dataset_object.getId()\n",
    "\n",
    "        files = sorted(folder.glob(\"*.ome.tif\"))\n",
    "\n",
    "        # process individual .ome.tif files\n",
    "        for file in files:\n",
    "            filename = file.stem\n",
    "            # load file\n",
    "            tf = tifffile.TiffFile(file)\n",
    "            # get summary metadata\n",
    "            summary_metadata = tf.micromanager_metadata['Summary']\n",
    "            nP, nT, nC, nZ, prefix, height, width, start_time = list(\n",
    "                summary_metadata[key] for key in (\n",
    "                    'Positions', \n",
    "                    'Frames', \n",
    "                    'Channels', \n",
    "                    'Slices', \n",
    "                    'Prefix',\n",
    "                    'Height',\n",
    "                    'Width',\n",
    "                    'StartTime'\n",
    "                    )\n",
    "                )\n",
    "            # get index map for page indices\n",
    "            index_map = tf.micromanager_metadata['IndexMap']\n",
    "        \n",
    "            for t in range(nT):\n",
    "                for z in range(nZ):\n",
    "                    page, pos, uid = toggel.find_page_id(index_map, c=0, z=z, t=t)\n",
    "                    micromanager_metadata = tf.pages[page].tags.get('MicroManagerMetadata').value\n",
    "                    metadata_values = list(\n",
    "                        micromanager_metadata[key] for key in (\n",
    "                            'PositionName',\n",
    "                            'PixelSizeUm', \n",
    "                            'ElapsedTime-ms', \n",
    "                            'Exposure-ms',\n",
    "                            'ReceivedTime',\n",
    "                            'Toggel-File basename', \n",
    "                            'Toggel-Frequency (MHz)', \n",
    "                            'Toggel-Number of Phases', \n",
    "                            'Toggel-Reference lifetime (ns)',\n",
    "                            'Toggel-Lower intensity threshold (DN)',\n",
    "                            'Nosepiece-Label',\n",
    "                            'IntermediateMagnification-Magnification',\n",
    "                            'XPositionUm',\n",
    "                            'YPositionUm',\n",
    "                            'ZPositionUm',\n",
    "                            'EM_Filter-Label',\n",
    "                            'EX_Filter-Label',\n",
    "                            'FilterTurret1-Label'\n",
    "                            )\n",
    "                        )\n",
    "                    # assign variables\n",
    "                    pos_label, pixel_size_um, elapsed_time_ms, exposure_ms, received_time, filebasename, frequency_mhz, nPhases, ref_lifetime, int_thr, obj, interMag, pos_x, pos_y, pos_z, emFilter, exFilter, dichroicMirror = metadata_values\n",
    "        \n",
    "                    # read experimental metadata from .csv file\n",
    "                    # get dataset-level experiment metadata\n",
    "                    dat_exp_metadata = subset[subset[\"Dataset\"]==prefix]\n",
    "\n",
    "                    \"\"\" \n",
    "                    check for position-level experiment metadata info\n",
    "                    \"\"\"\n",
    "                    if dat_exp_metadata.shape[0] == 0:\n",
    "                        print(\"Can't read experimental metadata for this dataset\")\n",
    "                        pos_dict = {k: \"empty\" for k, v in pos_dict.items()}\n",
    "                    else :\n",
    "                        if dat_exp_metadata.shape[0] > 1:\n",
    "                            pos_subset = dat_exp_metadata[dat_exp_metadata[\"Label\"] == pos_label] \n",
    "                        else :\n",
    "                            pos_subset = dat_exp_metadata\n",
    "                        #pos_subset = df[(df[\"Dataset\"]==prefix) & (df[\"Label\"]==pos_label)] \n",
    "                        \n",
    "                        # \"Dataset\" and \"Label\" values in .csv file must be the same as the prefix and pos_label values reads from the MicroManager metadata.\n",
    "                        # check for single row entry\n",
    "                        if pos_subset.shape[0] == 1:\n",
    "                            pos_dict = pos_subset.iloc[0].to_dict()\n",
    "                        else :                \n",
    "                            #pos_subset = dat_exp_metadata.iloc[0]\n",
    "                            pos_dict = dat_exp_metadata.iloc[0].to_dict()\n",
    "                            print(f\"check experimental metadata entry for {prefix} : {pos_label}.\")\n",
    "                            #break\n",
    "                    \n",
    "                    # initialise key-value pairs for adding as Map Annotation to OMERO image\n",
    "                    key_value_pairs = [[str(key), str(value)] for key, value in pos_dict.items() if not (isinstance(value, float) and np.isnan(value))]\n",
    "                    key_value_pairs.append([\"MicroManager_filename\", str(filename)])\n",
    "                    key_value_pairs.append([\"elapsed_time_ms\", str(elapsed_time_ms)])\n",
    "                    key_value_pairs.append([\"exposure_ms\", str(exposure_ms)])\n",
    "                    key_value_pairs.append([\"pixel_size_um\", str(pixel_size_um)])\n",
    "                    key_value_pairs.append([\"pos_label\", str(pos_label)])\n",
    "                    key_value_pairs.append([\"received_time\", str(received_time)])\n",
    "                    key_value_pairs.append([\"position_X\", str(pos_x)])\n",
    "                    key_value_pairs.append([\"position_Y\", str(pos_y)])\n",
    "                    key_value_pairs.append([\"position_Z\", str(pos_z)])\n",
    "                    key_value_pairs.append([\"T\", str(t)])\n",
    "                    key_value_pairs.append([\"size_T\", str(nT)])\n",
    "                    key_value_pairs.append([\"Z\", str(z)])\n",
    "                    key_value_pairs.append([\"size_Z\", str(nZ)])\n",
    "                    key_value_pairs.append([\"P\", str(pos)])\n",
    "                    key_value_pairs.append([\"Toggel-Number of Phases\", str(nPhases)])\n",
    "                    key_value_pairs.append([\"Objective\", str(obj)])\n",
    "                    key_value_pairs.append([\"FLIM_channel_emission_filter\", str(emFilter)])\n",
    "                    key_value_pairs.append([\"FLIM_channel_excitation_filter\", str(exFilter)])\n",
    "                    key_value_pairs.append([\"FLIM_channel_dichroic_mirror\", str(dichroicMirror)])\n",
    "        \n",
    "                    # find reference dataset (omero, HQL search for \"acquisition_type\" == 'reference', reference image before received_time\n",
    "                    # find reference file based on timestamp of .ome.tif file\n",
    "                    ref_name = toggel.find_phase_series_by_timestamp(ref_names, received_time, 'reference')\n",
    "                    ref_id = omero.get_image_id_from_image_name (conn, ref_name, project_id=toggel_project_id)\n",
    "                    reference_id = ref_id[0]\n",
    "\n",
    "                    key_value_pairs.append([\"reference_image_name\", str(ref_name)])\n",
    "                    key_value_pairs.append([\"reference_image_id\", str(reference_id)])\n",
    "\n",
    "                    # Get system calibration values\n",
    "                    if (reference_id != current_ref_id): \n",
    "                        # check to see if reference has already been used for calibration\n",
    "                        # load reference image object from omero\n",
    "                        ref_img_obj = conn.getObject(\"Image\", reference_id)\n",
    "\n",
    "                        # read reference metadata\n",
    "                        ref_metadata = omero.get_key_value_metadata (ref_img_obj)\n",
    "                        frequency = ref_metadata[\"modulation_frequency_Hz\"]\n",
    "                        ref_lifetime = ref_metadata[\"reference_lifetime_ns\"]\n",
    "                        n_phases = ref_metadata[\"n_phases\"]        \n",
    "\n",
    "                        # calculate expected values for reference lifetime with modulation frequency and number of phases\n",
    "                        omega, phases, phase_delay_radians, modulation_depth = toggel.calculate_expected_values (frequency, ref_lifetime, n_phases)\n",
    "                        key_value_pairs.append([\"omega\", str(omega)])\n",
    "                        key_value_pairs.append([\"frequency_Hz\", str(frequency)])\n",
    "\n",
    "                        # get phase series\n",
    "                        pixels = ref_img_obj.getPrimaryPixels()\n",
    "                        zct_list = [[0, 0, phase] for phase in range(int(n_phases))] # define zct_list\n",
    "                        ref_phase_series = omero.get_planes(zct_list, pixels)\n",
    "                        \n",
    "                        # calibrate reference\n",
    "                        ref_mean, A_fitted, phi_fitted, offset_fitted, phases, calibration_m, calibration_phi = toggel.calibrate_reference (ref_phase_series, phases, phase_delay_radians, modulation_depth, width, height)\n",
    "                        current_ref_id = reference_id\n",
    "\n",
    "                    \n",
    "\n",
    "                    # find phase series (omero, HQL search for \"acquisition_type\" == 'sample', sample image before received_time)\n",
    "                    phase_series_name = toggel.find_phase_series_by_timestamp(sample_names, received_time, 'sample')\n",
    "                    phase_series_id = omero.get_image_id_from_image_name (conn, phase_series_name, project_id=toggel_project_id)\n",
    "                    sample_object_id = phase_series_id[0]\n",
    "\n",
    "                    key_value_pairs.append([\"phase_series_image_name\", str(phase_series_name)])\n",
    "                    key_value_pairs.append([\"phase_series_image_id\", str(sample_object_id)])\n",
    "\n",
    "                    image_title = f\"{pos_label}_T{str(t).zfill(3)}_Z{str(z).zfill(3)}_{prefix}--ID{sample_object_id}\"\n",
    "\n",
    "                    # load phase series from omero\n",
    "                    sample_img_obj = conn.getObject(\"Image\", sample_object_id)\n",
    "                    # get phase series\n",
    "                    pixels = sample_img_obj.getPrimaryPixels()\n",
    "                    sample_phase_series = omero.get_planes(zct_list, pixels)\n",
    "\n",
    "                    ## DEFINE FITTING FUNCTIONS\n",
    "\n",
    "                    # Define a sine wave function to fit the data\n",
    "                    def sine_wave(x, amplitude, phase_shift, offset):\n",
    "                        phase_shift = (phase_shift + 180) % 360\n",
    "                        return amplitude * np.sin(x + phase_shift) + offset\n",
    "                    \n",
    "                    # Per-pixel fit function\n",
    "                    def fit_pixel(x, y):\n",
    "                        try:\n",
    "                            signal = sample_phase_series[:, x, y]\n",
    "                            signal_mean = signal.mean()\n",
    "                    \n",
    "                            # normalise signal to reference\n",
    "                            normalised_signal = signal / ref_mean[x, y]\n",
    "                            popt, _ = curve_fit(\n",
    "                                sine_wave,\n",
    "                                phases,\n",
    "                                normalised_signal,\n",
    "                                p0=[\n",
    "                                    A_fitted[x, y],\n",
    "                                    phi_fitted[x, y],\n",
    "                                    offset_fitted[x, y]\n",
    "                                ],\n",
    "                                maxfev=1000\n",
    "                            )\n",
    "                            # Extract fitted parameters (Amplitude, Phase shift, average/offset)\n",
    "                            sample_A_fitted, sample_phi_fitted, sample_offset_fitted = popt\n",
    "                    \n",
    "                            # Calibrate modulation\n",
    "                            sample_mod = calibration_m[x, y] * sample_A_fitted / sample_offset_fitted\n",
    "                        \n",
    "                            # Calculate phase\n",
    "                            sample_phi = abs(calibration_phi[x, y] + sample_phi_fitted)\n",
    "                            \n",
    "                            # Calculate lifetimes\n",
    "                            phase_lifetime_ps = (np.tan(sample_phi) / (2 * np.pi * frequency)) * 1e12\n",
    "                            mod_lifetime_ps = (np.sqrt(1 / sample_mod**2 - 1) / (2 * np.pi * frequency)) * 1e12\n",
    "                    \n",
    "                            # Calculate g and s values for phasor plotting    \n",
    "                            g = sample_mod * np.cos(sample_phi) # g value\n",
    "                            s = sample_mod * np.sin(sample_phi) # s value\n",
    "                    \n",
    "                            return x, y, g, s, phase_lifetime_ps, mod_lifetime_ps, signal_mean\n",
    "                        except Exception:\n",
    "                            return x, y, np.nan, np.nan, np.nan, np.nan, np.nan \n",
    "\n",
    "                    # check if processed image already exists in dataset\n",
    "\n",
    "                    dataset_object = conn.getObject(\"Dataset\", dataset_id)\n",
    "                    image_exists = None\n",
    "                    \n",
    "                    if dataset_object.countChildren() > 0:\n",
    "                        for child in dataset_object.listChildren():\n",
    "                            if child.getName() == str(image_title):\n",
    "                                image_exists = child\n",
    "                                break    \n",
    "                    \n",
    "                    if image_exists:\n",
    "                        print(f\"Image: {image_title} already exists in dataset.\")\n",
    "                    else :\n",
    "    \n",
    "                        # Mask of valid pixels\n",
    "                        int_min = np.min(sample_phase_series, axis=0)\n",
    "                        int_max = np.max(sample_phase_series, axis=0)\n",
    "    \n",
    "                        valid_pixels = np.argwhere(((int_min >= 0) & (int_max <= 15000))) # exclude pixels where the lowest value in the phase images is negative and max value is close to saturation/saturated\n",
    "                        \n",
    "                        # Run in parallel\n",
    "                        results = Parallel(n_jobs=-1, backend=\"loky\", verbose=5)(\n",
    "                            delayed(fit_pixel)(x, y) for x, y in valid_pixels\n",
    "                        )\n",
    "    \n",
    "                        # output arrays\n",
    "                        g_values_array = np.full((height, width), np.nan)\n",
    "                        s_values_array = np.full((height, width), np.nan)\n",
    "                        phase_tau_array = np.full((height, width), np.nan)\n",
    "                        mod_tau_array = np.full((height, width), np.nan)\n",
    "                        signal_int_array = np.full((height, width), np.nan)\n",
    "                        \n",
    "                        # populate with results\n",
    "                        for x, y, g, s, phase_tau, mod_tau, sig_int in results:\n",
    "                            # lifetime quality filter\n",
    "                            if ((0 <= g <= 1) & (0 <= s <= 1) & (0 < phase_tau <= 24000) & (0 < mod_tau <= 24000)):\n",
    "                                g_values_array[x, y] = g\n",
    "                                s_values_array[x, y] = s\n",
    "                                phase_tau_array[x, y] = phase_tau\n",
    "                                mod_tau_array[x, y] = mod_tau\n",
    "                                signal_int_array[x, y] = sig_int\n",
    "    \n",
    "                        # processed images to OMERO\n",
    "                        \n",
    "                        # ensure consistency of pixel type\n",
    "                        image_list = [arr.astype(np.float32) for arr in [signal_int_array, mod_tau_array, phase_tau_array, g_values_array, s_values_array]]\n",
    "                            \n",
    "                        # Stack into a 3D array (C, Y, X)\n",
    "                        image_stack = np.stack(image_list, axis=0)\n",
    "    \n",
    "                        # list of channel names\n",
    "                        channel_names = [\"intensity\", \"lifetime_modulation\", \"lifetime_phase\", \"g_values\", \"s_values\"]\n",
    "                        channel_labels = dict(enumerate(channel_names, start=1))\n",
    "                                \n",
    "                        # image description\n",
    "                        desc = f\"Frequency domain FLIM data processed from phase series from omero ID: {sample_object_id}\"\n",
    "\n",
    "                        # upload image to OMERO\n",
    "                        image_obj = omero.create_image(\n",
    "                            conn, image_title, dataset_id, key_value_pairs, image_stack, channel_names=channel_names, \n",
    "                            description=desc, sizeZ=1, sizeC=len(image_stack), sizeT=1, pixel_size_um = pixel_size_um\n",
    "                        )\n",
    "\n",
    "if (conn):\n",
    "    conn.close()\n",
    "    \n",
    "print(\"All FLIM images processed and uploaded to OMERO.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274405b1-0e3b-4388-b0e2-39ceb827429b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce59f17e-4f89-41c8-abe9-9b6dc2193d0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8670b73a-9fea-4ec3-bfb5-c9ede614c69c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32ecf24-406e-42a1-b707-4119699ffb11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00314153-3f81-4e11-a628-35d734656a57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce52cb7-9c76-40b7-b6b7-13c202b55b59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1fb5e01-e5ff-4267-962a-f3bf66cab191",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b8bbbe-790b-4d7d-92b4-77e2aa746d05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75eb07e0-3a45-4d2c-a9c1-4aeafa442b70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c530af-b33a-42cb-9f2a-8d577ac9b7be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079e5cf5-dac3-43eb-8281-8f795c2c55a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e248ad-11fa-49d1-8361-85104afd0c6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac21856f-0468-412f-a622-d1ed2701e238",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ac3e81-1c06-4c06-a3a0-5e01d2f6eded",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e63b8c5-6f3a-44a4-9c26-115e369d3574",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72025632-1595-4f75-b76e-75d13c055dd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741d19ca-0854-464e-a077-da6d8156f32c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e616a4-896d-42f8-8f67-820fbd1705fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be0017a-6af7-45c2-bdcb-56a13c7a066e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266cbdd0-e4f9-4452-aa5e-19b14290feb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f06490-1a64-4929-ab0d-8b35890e7ce8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b5405a-c46c-45ed-9a72-566e1ff7622c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5dda712-9d30-4c78-ab74-e70e67c1b79d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7cd52f9-3a62-421e-ba3e-ba59e549a57c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79fc7f9-12fa-4c7c-893f-0cbc7b2c429f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622f5e7f-a259-4160-8823-7978cfb4878e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05829ef5-ba9c-4390-933d-86a946bb9f89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f512fbfe-64ca-486f-ba69-b5177df80b1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c86104-655d-46b2-a546-5360f1dc1020",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4953d29-c341-4d22-af70-c1e6ab6394a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a74a0c4-f92f-41a2-b32e-78af39b582e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9da377a-07d2-42df-aba0-82660139b59e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55227c0a-4b27-4b79-9c78-53d915f604fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f054252-b1e0-4ab6-b9c7-3eaead36848a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b4eb24-faea-48ba-834a-848661571bca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e8f89e-53e1-4313-96a0-c3e261e9afb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "648871e0-9543-4161-ba89-827b1fa9a1bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
